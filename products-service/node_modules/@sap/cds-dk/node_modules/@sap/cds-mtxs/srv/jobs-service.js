const { inspect } = require('util')
const cds = require('@sap/cds/lib'), { uuid } = cds.utils
const { retry } = require('../lib/utils')
const LOG = cds.log('mtx')

const Jobs = 'cds.xt.Jobs', Tasks = 'cds.xt.Tasks'

const t0 = cds.env.requires.multitenancy.t0 ?? 't0'

const {
  clusterSize = 1, workerSize = 1, poolSize = 1
} = cds.env.requires.multitenancy.jobs ?? cds.env.requires['cds.xt.SaasProvisioningService']?.jobs ?? {}

const RUNNING = 'RUNNING', FINISHED = 'FINISHED', FAILED = 'FAILED'

module.exports = class JobsService extends cds.ApplicationService {

  async enqueue(clusters, op, args = [], onJobDone) {
    const _args = args.length > 0 ? ['with args', inspect(args.filter(Boolean), { depth: 5, colors: true })] : []
    LOG.info(`enqueuing '${op}' job for`, clusters, ..._args)

    const job_ID = uuid()
    const job = { ID: job_ID, createdAt: (new Date).toISOString(), op }
    await retry(() => cds.tx({ tenant: t0 }, tx => tx.run(INSERT.into(Jobs, job))), LOG)
    const jobs = clusters?.map(cluster => Array.from(cluster).map(tenant => ({ job_ID, ID: uuid(), tenant, op }))) ?? []
    const tasks = jobs.flat()

    if (tasks.length) {
      await retry(() => cds.tx({ tenant: t0 }, tx => tx.run(INSERT.into(Tasks, tasks))), LOG)

      _nextJob(jobs, task => {
        const { 'cds.xt.DeploymentService': ds } = cds.services
        return ds.tx({ tenant: cds.context.tenant }, tx => tx[op](task.tenant, ...args))
      }, onJobDone).catch(err => LOG.error('next job raised an error', err))
    } else {
      await retry(() => cds.tx({ tenant: t0 }, tx =>
        tx.run(UPDATE(Jobs, { ID: job_ID }).with({ status: FINISHED }))
      ), LOG)
    }

    const url = process.env.VCAP_APPLICATION ? 'https://' + JSON.parse(process.env.VCAP_APPLICATION).uris?.[0] : cds.server.url
    cds.context.http?.res.set('Location', `${url}/-/cds/jobs/pollJob(ID='${job_ID}')`)
    cds.context.http?.res.set('x-job-id', job_ID)
    cds.context.http?.res.status(202)
    return {
      ...job,
      tenants: Object.fromEntries(tasks.map(task =>
        [task.tenant, { ...task, job_ID: undefined, tenant: undefined, op: undefined }]
      ))
    }
  }

  async pollJob(ID) {
    const job = await cds.tx({ tenant: t0 }, tx =>
      tx.run(SELECT.one.from(Jobs).where({ ID }))
    )
    if (!job) cds.error(`No job found for ID ${ID}`, { status: 404 })
    let tenants
    if (job.status ?? job.STATUS in { FINISHED: 1, FAILED: 1 }) {
      tenants = Object.fromEntries((await cds.tx({ tenant: t0 }, tx =>
        tx.run(SELECT.from(Tasks).where({ job_ID: job.ID }))
      )).map(task => [task.tenant ?? task.TENANT, {
        status: task.status ?? task.STATUS,
        error: task.error ?? task.ERROR ?? undefined
      }]))
    }
    return {
      status: job.status ?? job.STATUS,
      op: job.op ?? job.OP,
      tenants
    }
  }

  async pollTask(ID) {
    const task = await cds.tx({ tenant: t0 }, tx =>
      tx.run(SELECT.one.from(Tasks).where({ ID }))
    )
    return {
      status: task.status ?? task.STATUS,
      op: task.op ?? task.OP,
      error: task.error ?? task.ERROR ?? undefined
    }
  }
}

async function limiter(limit, payloads, fn, asTask = false) {
  const pending = [], all = []
  for (const payload of payloads) {
    const execute = asTask ? _nextTask(payload, fn(payload)) : fn(payload)
    all.push(execute)
    const executeAndRemove = execute.catch(() => {}).finally(() => pending.splice(pending.indexOf(executeAndRemove), 1))
    pending.push(executeAndRemove)
    if (pending.length >= limit) {
      await Promise.race(pending)  // eslint-disable-line no-await-in-loop
    }
  }
  return Promise.allSettled(all)
}

async function _nextJob(clusters, fn, onJobDone) {
  if (clusters.length > 1) {
    await limiter(clusterSize, clusters, cluster => limiter(workerSize ?? poolSize, Array.from(cluster), fn, true))
  } else {
    await limiter(workerSize ?? poolSize, Array.from(clusters[0]), fn, true)
  }

  const { job_ID } = clusters.flat()[0] // all tasks have the same job ID -> just take the first
  const failed = await retry(() => cds.tx({ tenant: t0 }, tx =>
    tx.run(SELECT.one.from(Tasks).where ({ job_ID, and: { status: FAILED }}))
  ), LOG)
  const running = await retry(() => cds.tx({ tenant: t0 }, tx =>
    tx.run(SELECT.one.from(Tasks).where ({ job_ID, and: { status: RUNNING }}))
  ), LOG)

  if (failed) {
    await retry(() => cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Jobs, { ID: job_ID }).with({ status: FAILED }))
    ), LOG)
    if (onJobDone) await onJobDone(failed.error ?? failed.ERROR)
  } else if (!running) {
    await retry(() => cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Jobs, { ID: job_ID }).with({ status: FINISHED }))
    ), LOG)
    if (onJobDone) await onJobDone()
  }
}

async function _nextTask(task, _fn) {
  const { ID, tenant } = task
  let hasErrored = false
  try {
    return await _fn
  } catch (e) {
    LOG.error(e)
    hasErrored = true
    await retry(() => cds.tx({ tenant: t0 }, tx =>
      tx.run(UPDATE(Tasks, { ID, tenant }).with({ status: FAILED, error: e.message }))
    ), LOG)
  } finally {
    if (!hasErrored) {
      await retry(() => cds.tx({ tenant: t0 }, tx =>
        tx.run(UPDATE(Tasks, { ID, tenant }).with({ status: FINISHED }))
      ), LOG)
    }
  }
}

if (cds.requires.multitenancy.jobCleanup !== false) {

  // Cleanup finished/failed jobs
  const jobCleanup = setInterval(async () => {
    const cutoff = new Date(new Date - (cds.env.requires.multitenancy.jobCleanupAge ?? 1000 * 60 * 60 * 24)) // a day
    await cds.tx({ tenant: t0 },
      tx => tx.run(DELETE.from(Jobs, { status: FAILED, or: { status: FINISHED, and: { createdAt: { '<': cutoff.toISOString() }}}}))
    )
  }, cds.env.requires.multitenancy.jobCleanupInterval ?? 1000 * 60 * 60 * 24) // once a day
  jobCleanup.unref()

  // Cleanup stale jobs
  const jobCleanupStale = setInterval(async () => {
    const cutoff = new Date(new Date - (cds.env.requires.multitenancy.jobCleanupAgeStale ?? 1000 * 60 * 60 * 24 * 7)) // a week
    await cds.tx({ tenant: t0 },
      tx => tx.run(DELETE.from(Jobs, { createdAt: { '<': cutoff.toISOString() }}))
    )
  }, cds.env.requires.multitenancy.jobCleanupIntervalStale ?? 1000 * 60 * 60 * 24 * 7) // once a week
  jobCleanupStale.unref()

}
